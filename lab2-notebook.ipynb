{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ba3771",
   "metadata": {},
   "source": [
    "# Lab 2 for EC3318/MN3101 Corporate Finance\n",
    "\n",
    "## Modern Portfolio Theory with PyPortfolioOpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dff8b5",
   "metadata": {},
   "source": [
    "## 1. Setup and data recap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2ab2b",
   "metadata": {},
   "source": [
    "### Introduction to Modern Portfolio Theory\n",
    "\n",
    "**Modern Portfolio Theory (MPT)**, developed by Harry Markowitz in 1952, revolutionized investment management by providing a mathematical framework for constructing portfolios that optimize the trade-off between expected return and risk (measured as variance). The key insight is that portfolio risk depends not just on individual asset volatilities, but critically on the **correlations** between assets—enabling diversification benefits.\n",
    "\n",
    "In this lab, you will:\n",
    "\n",
    "1. Load and prepare historical stock return data\n",
    "2. Estimate key inputs (expected returns and covariance matrix) for portfolio optimization\n",
    "3. Apply mean-variance optimization to find **efficient portfolios**\n",
    "4. Understand the **efficient frontier** and the **tangency portfolio** (maximum Sharpe ratio)\n",
    "5. Explore how constraints (e.g., no short-selling) affect optimal portfolios\n",
    "6. Translate optimal weights into actionable trade recommendations\n",
    "\n",
    "We'll use **PyPortfolioOpt**, a Python library that implements these concepts with robust numerical optimization methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a32508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core data manipulation libraries\n",
    "import pandas as pd  # For working with tabular data (DataFrames)\n",
    "import numpy as np  # For numerical operations and array computations\n",
    "\n",
    "# Import PyPortfolioOpt components for portfolio optimization\n",
    "from pypfopt import (\n",
    "    EfficientFrontier,  # Main class for mean-variance optimization\n",
    "    risk_models,  # Functions to estimate covariance matrices\n",
    "    expected_returns,  # Functions to estimate expected returns\n",
    "    objective_functions,  # Additional objectives like L2 regularization\n",
    ")\n",
    "\n",
    "# Import discrete allocation tools to convert weights to actual share counts\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "\n",
    "# Import convex optimization library (used internally by PyPortfolioOpt)\n",
    "import cvxpy as cp\n",
    "import cvxpy.constraints\n",
    "\n",
    "# Import visualization library (ggplot-style grammar of graphics for Python)\n",
    "from plotnine import *\n",
    "from plotnine import options as p9_options\n",
    "from mizani.formatters import percent_format  # Format axis labels as percentages\n",
    "from adjustText import adjust_text  # Automatically adjust text labels to avoid overlap\n",
    "\n",
    "# Set default figure size for all plots\n",
    "p9_options.figure_size = (8, 6)\n",
    "\n",
    "# Configure pandas display options to show full outputs without truncation\n",
    "pd.set_option(\"display.max_rows\", None)  # Show all rows in output\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns in output\n",
    "pd.set_option(\"display.width\", None)  # Auto-detect terminal width\n",
    "pd.set_option(\"display.max_colwidth\", None)  # Show full column content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf9e16",
   "metadata": {},
   "source": [
    "### Loading and Preparing Return Data\n",
    "\n",
    "The foundation of any portfolio optimization is high-quality **historical return data**. Here we load monthly adjusted closing prices from an Excel file and transform them into returns.\n",
    "\n",
    "**Key data transformations:**\n",
    "\n",
    "1. **Convert Excel date format**: Excel stores dates as numbers (days since 1899-12-30)\n",
    "2. **Reshape from wide to long format**: Using `melt()` to create a tidy structure\n",
    "3. **Calculate returns**: Compute percentage changes within each stock using `groupby()`\n",
    "4. **Handle missing values**: Drop NaN values from the first return observation\n",
    "\n",
    "This tidy data structure (one row per stock-date pair) makes subsequent analysis much easier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a78328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical stock price data and calculate returns\n",
    "returns = (\n",
    "    pd.read_excel(\n",
    "        io=\"downloading_stock_prices.xlsx\",  # Excel file with price data\n",
    "        sheet_name=\"Data download\",  # Specific sheet name\n",
    "        skiprows=7,  # Skip header rows\n",
    "    )\n",
    "    # Convert Excel serial date numbers to proper datetime objects\n",
    "    .assign(date=lambda x: pd.to_datetime(x[\"date\"], unit=\"D\", origin=\"1899-12-30\"))\n",
    "    # Transform from wide format (one column per stock) to long format (one row per stock-date)\n",
    "    .melt(id_vars=\"date\", var_name=\"symbol\", value_name=\"adj_close\")\n",
    "    # Sort by stock symbol and then by date for proper time series ordering\n",
    "    .sort_values([\"symbol\", \"date\"])\n",
    "    # Reset index after sorting\n",
    "    .reset_index(drop=True)\n",
    "    # Calculate percentage returns for each stock separately using groupby\n",
    "    # pct_change() computes (price_t - price_{t-1}) / price_{t-1}\n",
    "    .assign(ret=lambda df: df.groupby(\"symbol\")[\"adj_close\"].pct_change())\n",
    "    # Remove the first observation for each stock (which has NaN return)\n",
    "    .dropna()\n",
    ")\n",
    "# Display first few rows to verify data structure\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4807613",
   "metadata": {},
   "source": [
    "### Summary Statistics by Stock\n",
    "\n",
    "Before optimization, it's crucial to understand the characteristics of each asset. We compute **descriptive statistics** for the return distribution of each stock:\n",
    "\n",
    "- **Count**: Number of monthly observations\n",
    "- **Mean**: Average return (a simple estimate of expected return)\n",
    "- **Std**: Standard deviation (volatility/risk)\n",
    "- **Min/Max**: Range of observed returns\n",
    "\n",
    "These statistics reveal which assets have historically delivered higher returns and which are more volatile. Note that past performance doesn't guarantee future results—one of the key challenges in portfolio optimization!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e073d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for each stock through groupby-aggregation\n",
    "summary_stats = (\n",
    "    returns.groupby(\"symbol\")[\"ret\"]  # Group returns by stock symbol\n",
    "    .agg(\n",
    "        [\"count\", \"mean\", \"std\", \"min\", \"max\"]\n",
    "    )  # Calculate multiple statistics at once\n",
    "    .round(3)  # Round to 3 decimal places for readability\n",
    "    .reset_index()  # Convert index (symbol) back to a regular column\n",
    ")\n",
    "# Display the summary statistics table\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a817b",
   "metadata": {},
   "source": [
    "## 3. Estimating inputs for Markowitz optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed817623",
   "metadata": {},
   "source": [
    "### Why Annualization Matters\n",
    "\n",
    "Financial returns are often reported at different frequencies (daily, monthly, annual). For portfolio analysis, we typically **annualize** returns and volatilities to:\n",
    "\n",
    "1. Make comparisons across different datasets easier\n",
    "2. Express results in intuitive yearly terms\n",
    "3. Align with industry standards (Sharpe ratios, target returns, etc.)\n",
    "\n",
    "**Annualization formulas:**\n",
    "\n",
    "- **Expected return**: Multiply by the number of periods per year\n",
    "  - Monthly: $\\mu_{\\text{annual}} = 12 \\times \\mu_{\\text{monthly}}$\n",
    "- **Volatility (standard deviation)**: Multiply by the square root of periods per year\n",
    "  - Monthly: $\\sigma_{\\text{annual}} = \\sqrt{12} \\times \\sigma_{\\text{monthly}}$\n",
    "\n",
    "This follows from the properties of independently distributed returns: variance scales linearly with time, but standard deviation scales with the square root of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set annualization factor for monthly data (12 months per year)\n",
    "# This will be used to convert monthly statistics to annual equivalents\n",
    "annualisation_factor = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83344b50",
   "metadata": {},
   "source": [
    "### Visualizing the Risk-Return Trade-off\n",
    "\n",
    "This scatter plot shows the **risk-return profile** of each asset in our investment universe. Each point represents one stock, positioned according to its:\n",
    "\n",
    "- **X-axis**: Annualized volatility (risk)\n",
    "- **Y-axis**: Annualized expected return (reward)\n",
    "\n",
    "**Key insights from this plot:**\n",
    "\n",
    "- Assets in the **upper-left** quadrant are desirable (high return, low risk)\n",
    "- Assets in the **lower-right** are undesirable (low return, high risk)\n",
    "- The **correlation structure** between assets (not shown here) determines diversification benefits\n",
    "- No individual asset dominates all others—this creates opportunities for portfolio construction\n",
    "\n",
    "The goal of MPT is to combine these assets to create portfolios that lie **above and to the left** of any individual asset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62528b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create asset summary with expected returns and volatilities\n",
    "asset_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"symbol\": summary_stats[\"symbol\"],  # Stock ticker symbols\n",
    "        \"mu\": summary_stats[\"mean\"],  # Mean monthly return (not annualized yet)\n",
    "        \"sigma\": summary_stats[\"std\"]\n",
    "        * np.sqrt(annualisation_factor),  # Annualized volatility\n",
    "    }\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Create enhanced scatter plot with better text positioning\n",
    "assets_figure = (\n",
    "    # Initialize plot with data and aesthetic mappings\n",
    "    ggplot(asset_summary, aes(x=\"sigma\", y=\"mu\", label=\"symbol\"))\n",
    "    # Add points for each asset\n",
    "    + geom_point(size=3, alpha=0.7)\n",
    "    # Add text labels with automatic adjustment to prevent overlap\n",
    "    + geom_text(adjust_text={\"arrowprops\": {\"arrowstyle\": \"-\"}})\n",
    "    # Format x-axis as percentages\n",
    "    + scale_x_continuous(labels=percent_format())\n",
    "    # Format y-axis as percentages\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    # Add informative labels\n",
    "    + labs(\n",
    "        x=\"Volatility (annualised)\",\n",
    "        y=\"Expected return (annualised)\",\n",
    "        title=\"Expected returns and volatilities of portfolio constituents\",\n",
    "        subtitle=\"Based on historical monthly returns\",\n",
    "    )\n",
    "    # Use clean, professional theme\n",
    "    + theme_minimal()\n",
    "    # Set custom figure size\n",
    "    + theme(figure_size=(10, 7))\n",
    ")\n",
    "# Display the plot\n",
    "assets_figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0874d13",
   "metadata": {},
   "source": [
    "### Estimating Expected Returns\n",
    "\n",
    "**Expected returns** are notoriously difficult to estimate—they have high estimation error and are unstable over time. Here we use **historical mean returns** as our estimate.\n",
    "\n",
    "PyPortfolioOpt provides the `mean_historical_return()` function which:\n",
    "\n",
    "1. Calculates the arithmetic mean of historical returns for each asset\n",
    "2. Annualizes the result using the specified frequency\n",
    "3. Returns a pandas Series indexed by asset symbols\n",
    "\n",
    "**Critical caveat**: Historical returns are often poor predictors of future returns. In practice, practitioners may:\n",
    "\n",
    "- Use more sophisticated forecasting models\n",
    "- Apply **shrinkage** methods (Black-Litterman, Bayes-Stein)\n",
    "- Incorporate **fundamental analysis** or **analyst forecasts**\n",
    "- Use **equal-weighted** or **minimum-variance** approaches that don't rely heavily on return estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data from long format to wide format (needed for PyPortfolioOpt functions)\n",
    "# Each column represents one stock, each row represents one date\n",
    "prices_wide = returns.get([\"date\", \"symbol\", \"adj_close\"]).pivot(\n",
    "    index=\"date\", columns=\"symbol\", values=\"adj_close\"\n",
    ")\n",
    "\n",
    "# Calculate mean historical returns for each asset (annualized)\n",
    "mu = expected_returns.mean_historical_return(\n",
    "    prices_wide, frequency=annualisation_factor  # Converts monthly to annual\n",
    ")\n",
    "\n",
    "# Display expected returns as a DataFrame (transposed for better readability)\n",
    "pd.DataFrame({\"expected_return\": mu}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf4230",
   "metadata": {},
   "source": [
    "### Estimating the Covariance Matrix\n",
    "\n",
    "The **covariance matrix** is the heart of portfolio optimization. It captures:\n",
    "\n",
    "- **Variances** (diagonal elements): How volatile each asset is\n",
    "- **Covariances** (off-diagonal elements): How assets move together\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "- **Positive covariance**: Assets tend to move in the same direction (less diversification benefit)\n",
    "- **Negative covariance**: Assets move in opposite directions (strong diversification benefit)\n",
    "- **Zero covariance**: Assets move independently (moderate diversification benefit)\n",
    "\n",
    "The `sample_cov()` function computes the sample covariance matrix from historical returns and annualizes it. This matrix is:\n",
    "\n",
    "- **Symmetric**: $\\Sigma_{ij} = \\Sigma_{ji}$\n",
    "- **Positive semidefinite**: All eigenvalues are non-negative (required for optimization)\n",
    "\n",
    "**Estimation challenges:**\n",
    "\n",
    "- For $N$ assets, we must estimate $N(N+1)/2$ parameters\n",
    "- With limited data, estimation error can be substantial\n",
    "- Advanced methods (shrinkage, factor models) can improve estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aa23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample covariance matrix (annualized)\n",
    "# This captures both individual asset volatilities and co-movements between assets\n",
    "cov_matrix = risk_models.sample_cov(prices_wide, frequency=annualisation_factor)\n",
    "# Display the covariance matrix\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1w3fujb1wtw",
   "metadata": {},
   "source": [
    "## 4. Mean–variance optimization theory\n",
    "\n",
    "Let's build some intuition starting with a simple **two-asset** portfolio, then see how the same ideas scale up using **matrix notation** for many assets.\n",
    "\n",
    "### Two risky assets\n",
    "\n",
    "Consider two assets, **A** and **B**.\n",
    "\n",
    "- Expected returns: $\\mu_A, \\mu_B$\n",
    "- Standard deviations: $\\sigma_A, \\sigma_B$\n",
    "- Correlation: $\\rho_{AB}$\n",
    "- Portfolio weight in A: $w$ (so weight in B is $1-w$)\n",
    "\n",
    "#### Portfolio expected return\n",
    "\n",
    "$$\\mu_p = w\\,\\mu_A + (1-w)\\,\\mu_B$$\n",
    "\n",
    "#### Portfolio risk (variance)\n",
    "\n",
    "$$\\sigma_p^2 = w^2\\sigma_A^2 + (1-w)^2\\sigma_B^2 + 2w(1-w)\\rho_{AB}\\sigma_A\\sigma_B$$\n",
    "\n",
    "- If $\\rho_{AB}=1$: no diversification benefit.\n",
    "- If $\\rho_{AB}<1$: diversification reduces risk.\n",
    "- If $\\rho_{AB}=-1$: perfect negative correlation can theoretically eliminate risk entirely.\n",
    "\n",
    "#### The opportunity set and the minimum-variance portfolio (MVP)\n",
    "\n",
    "As $w$ varies from 0 to 1, the point $(\\sigma_p,\\mu_p)$ traces out a curve called the **two-asset opportunity set**.  \n",
    "The **MVP** sits at the lowest point on this curve. Its weight on A is:\n",
    "$$w_A^{\\text{mvp}} = \\frac{\\sigma_B^2 - \\rho_{AB}\\sigma_A\\sigma_B}{\\sigma_A^2 + \\sigma_B^2 - 2\\rho_{AB}\\sigma_A\\sigma_B}, \\quad w_B^{\\text{mvp}} = 1 - w_A^{\\text{mvp}}$$\n",
    "\n",
    "> If short-selling is **forbidden**, we clip weights to $[0,1]$ and pick the lowest-variance feasible point.\n",
    "\n",
    "#### Hitting a target return with two assets\n",
    "\n",
    "With only two assets (and full investment), the weight that achieves target return $\\mu_p$ is:\n",
    "$$w = \\frac{\\mu_p - \\mu_B}{\\mu_A - \\mu_B}, \\quad 1-w = \\frac{\\mu_A - \\mu_p}{\\mu_A - \\mu_B}$$\n",
    "This is already the minimum-variance way to reach $\\mu_p$ using just A and B.\n",
    "\n",
    "#### Adding a risk-free asset\n",
    "\n",
    "Let the risk-free rate be $r_f$. Pick any risky portfolio $R$ (a mix of A and B) and combine it with $r_f$ to get a straight **Capital Allocation Line (CAL)** with slope (Sharpe ratio):\n",
    "$$\\text{Sharpe}(R) = \\frac{\\mu_R - r_f}{\\sigma_R}$$\n",
    "The **tangency portfolio** $R^\\ast$ (a particular mix of A and B) maximizes this slope.\n",
    "\n",
    "### From 2 assets to many (matrix view)\n",
    "\n",
    "Matrix notation simply extends the same concepts to $N$ assets in a compact form.\n",
    "\n",
    "- **Weights:** $\\boldsymbol{\\omega}\\in\\mathbb{R}^N$ with $\\boldsymbol{\\omega}^\\top \\mathbf{1}=1$\n",
    "- **Expected returns:** $\\boldsymbol{\\mu}\\in\\mathbb{R}^N$\n",
    "- **Covariance matrix:** $\\Sigma\\in\\mathbb{R}^{N\\times N}$ (symmetric, positive semidefinite)\n",
    "- **Ones vector:** $\\mathbf{1}\\in\\mathbb{R}^N$\n",
    "\n",
    "#### Portfolio return and variance\n",
    "\n",
    "$$\\mu_p = \\boldsymbol{\\omega}^\\top \\boldsymbol{\\mu}, \\quad \\sigma_p^2 = \\boldsymbol{\\omega}^\\top \\Sigma \\boldsymbol{\\omega}$$\n",
    "\n",
    "#### Minimum-variance portfolio (MVP)\n",
    "\n",
    "$$\\boldsymbol{\\omega}_{\\text{mvp}} = \\frac{\\Sigma^{-1}\\mathbf{1}}{\\mathbf{1}^\\top \\Sigma^{-1}\\mathbf{1}}$$\n",
    "\n",
    "#### Tangency portfolio (with risk-free rate $r_f$)\n",
    "\n",
    "$$\\boldsymbol{\\omega}_{\\text{tan}} = \\frac{\\Sigma^{-1}\\big(\\boldsymbol{\\mu}-r_f\\mathbf{1}\\big)}{\\mathbf{1}^\\top \\Sigma^{-1}\\big(\\boldsymbol{\\mu}-r_f\\mathbf{1}\\big)}$$\n",
    "\n",
    "This is the unique risky portfolio that maximizes the Sharpe ratio. Any point on the CAL is just a mix of $\\boldsymbol{\\omega}_{\\text{tan}}$ with the risk-free asset.\n",
    "\n",
    "#### General (target-return) problem\n",
    "\n",
    "$$\\min_{\\boldsymbol{\\omega}}\\;\\boldsymbol{\\omega}^\\top\\Sigma\\,\\boldsymbol{\\omega} \\quad \\text{subject to} \\quad \\boldsymbol{\\omega}^\\top\\boldsymbol{\\mu}=\\mu_p, \\; \\boldsymbol{\\omega}^\\top\\mathbf{1}=1$$\n",
    "This has a closed-form solution (via Lagrange multipliers) and is computationally fast even for large $N$.\n",
    "\n",
    "### Key takeaways\n",
    "\n",
    "- The two-asset case builds intuition: returns combine linearly, risk is curved, and there's a closed-form MVP.\n",
    "- With a risk-free asset, the **tangency portfolio** is the optimal risky mix; you then scale it up or down based on your risk appetite.\n",
    "- Matrix notation is just a compact, scalable way to express these same ideas for many assets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108eca0b",
   "metadata": {},
   "source": [
    "## 5. The efficient frontier and tangency portfolio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9264c",
   "metadata": {},
   "source": [
    "### What is the Efficient Frontier?\n",
    "\n",
    "The **efficient frontier** is the set of portfolios that offer the highest expected return for each level of risk (or equivalently, the lowest risk for each level of return). It represents the \"best\" possible portfolios available.\n",
    "\n",
    "**Key concepts:**\n",
    "\n",
    "- **Dominated portfolios**: Any portfolio not on the efficient frontier is dominated—you could achieve higher return for the same risk or lower risk for the same return\n",
    "- **Tangency portfolio**: The portfolio on the efficient frontier with the highest **Sharpe ratio** (reward-to-risk ratio): $\\text{Sharpe} = \\frac{\\mu_p - r_f}{\\sigma_p}$\n",
    "- **Two-fund separation theorem**: When a risk-free asset exists, all investors should hold the same risky portfolio (the tangency portfolio) combined with the risk-free asset\n",
    "\n",
    "### Maximum Sharpe Ratio Portfolio (Tangency Portfolio)\n",
    "\n",
    "The **tangency portfolio** is typically the most important portfolio in practice because:\n",
    "\n",
    "1. It offers the best risk-adjusted returns\n",
    "2. It serves as the optimal risky portfolio for all investors\n",
    "3. Risk-averse investors hold more of the risk-free asset; risk-seeking investors leverage it\n",
    "\n",
    "We add **L2 regularization** (Ridge penalty) with $\\gamma = 0.01$ to:\n",
    "\n",
    "- Prevent extreme portfolio weights\n",
    "- Improve numerical stability\n",
    "- Reduce sensitivity to estimation error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea11292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create efficient frontier object and compute portfolios\n",
    "# Initialize with expected returns (mu) and covariance matrix\n",
    "ef_sharpe = EfficientFrontier(mu, cov_matrix)\n",
    "# Add L2 regularization to penalize extreme weights (gamma controls strength)\n",
    "ef_sharpe.add_objective(objective_functions.L2_reg, gamma=0.01)\n",
    "\n",
    "# Maximum Sharpe ratio portfolio (tangency portfolio)\n",
    "# This solves: max (mu_p - r_f) / sigma_p where r_f = 0 by default\n",
    "max_sharpe_weights = ef_sharpe.max_sharpe()\n",
    "# Clean weights: remove tiny positions (below threshold) for practical implementation\n",
    "cleaned_max_sharpe = ef_sharpe.clean_weights()\n",
    "# Calculate portfolio performance metrics (expected return, volatility, Sharpe ratio)\n",
    "max_sharpe_perf = ef_sharpe.portfolio_performance(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MAXIMUM SHARPE RATIO PORTFOLIO\")\n",
    "print(\"=\" * 50)\n",
    "# Convert weights dictionary to DataFrame and sort by weight size\n",
    "max_sharpe_weights_df = (\n",
    "    pd.Series(cleaned_max_sharpe, name=\"weight\").sort_values(ascending=False).to_frame()\n",
    ")\n",
    "# Create metrics series for cleaner display\n",
    "max_sharpe_metrics = pd.Series(\n",
    "    max_sharpe_perf,\n",
    "    index=[\"expected_return\", \"volatility\", \"sharpe_ratio\"],\n",
    "    name=\"max_sharpe_portfolio\",\n",
    ")\n",
    "print(\"Portfolio weights:\")\n",
    "print(max_sharpe_weights_df)\n",
    "print(f\"\\nPerformance metrics:\")\n",
    "print(max_sharpe_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0c0ad",
   "metadata": {},
   "source": [
    "### Minimum Volatility Portfolio (MVP)\n",
    "\n",
    "The **minimum volatility portfolio** is the portfolio with the lowest possible risk. It lies at the leftmost point of the efficient frontier.\n",
    "\n",
    "**Key characteristics:**\n",
    "\n",
    "- Focuses purely on risk minimization (ignores expected returns)\n",
    "- Typically highly diversified across many assets\n",
    "- Often has lower returns than the tangency portfolio\n",
    "- Suitable for very risk-averse investors\n",
    "- More stable over time than return-focused portfolios (less sensitive to return estimation errors)\n",
    "\n",
    "**Mathematical formulation:**\n",
    "$$\\min_{\\boldsymbol{\\omega}} \\; \\boldsymbol{\\omega}^\\top \\Sigma \\boldsymbol{\\omega} \\quad \\text{subject to} \\quad \\boldsymbol{\\omega}^\\top \\mathbf{1} = 1$$\n",
    "\n",
    "The MVP is popular because:\n",
    "\n",
    "1. It doesn't require expected return estimates (which are notoriously unreliable)\n",
    "2. It's relatively stable and robust\n",
    "3. Historically, it has often performed well out-of-sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54500ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum volatility portfolio\n",
    "# Create a fresh EfficientFrontier object (each optimization needs its own instance)\n",
    "ef_min_vol = EfficientFrontier(mu, cov_matrix)\n",
    "# Add L2 regularization to prevent extreme weights\n",
    "ef_min_vol.add_objective(objective_functions.L2_reg, gamma=0.01)\n",
    "# Optimize for minimum volatility (ignores expected returns)\n",
    "min_vol_weights = ef_min_vol.min_volatility()\n",
    "# Clean up small weights for practical implementation\n",
    "cleaned_min_vol = ef_min_vol.clean_weights()\n",
    "# Calculate performance metrics\n",
    "min_vol_perf = ef_min_vol.portfolio_performance(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MINIMUM VOLATILITY PORTFOLIO\")\n",
    "print(\"=\" * 50)\n",
    "# Convert weights to DataFrame and sort\n",
    "min_vol_weights_df = (\n",
    "    pd.Series(cleaned_min_vol, name=\"weight\").sort_values(ascending=False).to_frame()\n",
    ")\n",
    "# Create metrics series\n",
    "min_vol_metrics = pd.Series(\n",
    "    min_vol_perf,\n",
    "    index=[\"expected_return\", \"volatility\", \"sharpe_ratio\"],\n",
    "    name=\"min_vol_portfolio\",\n",
    ")\n",
    "print(\"Portfolio weights:\")\n",
    "print(min_vol_weights_df)\n",
    "print(f\"\\nPerformance metrics:\")\n",
    "print(min_vol_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c620d",
   "metadata": {},
   "source": [
    "### Target Return Portfolio\n",
    "\n",
    "Sometimes investors have a **specific return target** in mind (e.g., \"I need 8% annual return\"). The `efficient_return()` method finds the portfolio on the efficient frontier that achieves this target with **minimum risk**.\n",
    "\n",
    "**Mathematical formulation:**\n",
    "$$\\min_{\\boldsymbol{\\omega}} \\; \\boldsymbol{\\omega}^\\top \\Sigma \\boldsymbol{\\omega} \\quad \\text{subject to} \\quad \\boldsymbol{\\omega}^\\top \\boldsymbol{\\mu} = \\mu_{\\text{target}}, \\; \\boldsymbol{\\omega}^\\top \\mathbf{1} = 1$$\n",
    "\n",
    "**Important notes:**\n",
    "\n",
    "- The target must be **feasible** (between the minimum and maximum achievable returns)\n",
    "- If target is too high, optimization will fail\n",
    "- If target equals MVP return, you get the MVP\n",
    "- If target equals max Sharpe return, you get the tangency portfolio\n",
    "\n",
    "Here we use the mean of all asset returns as our target, ensuring it's feasible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3304e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a target return (clipped to feasible range for safety)\n",
    "target_return = float(np.clip(mu.mean(), mu.min(), mu.max()))\n",
    "# Create fresh EfficientFrontier object\n",
    "ef_target = EfficientFrontier(mu, cov_matrix)\n",
    "# Add L2 regularization\n",
    "ef_target.add_objective(objective_functions.L2_reg, gamma=0.01)\n",
    "# Optimize to achieve target return with minimum risk\n",
    "target_weights = ef_target.efficient_return(target_return=target_return)\n",
    "# Clean weights\n",
    "cleaned_target = ef_target.clean_weights()\n",
    "# Calculate performance (verbose=False to suppress output)\n",
    "target_perf = ef_target.portfolio_performance(verbose=False)\n",
    "\n",
    "# Convert to DataFrames for display\n",
    "target_weights_df = (\n",
    "    pd.Series(cleaned_target, name=\"weight\").sort_values(ascending=False).to_frame()\n",
    ")\n",
    "target_metrics = pd.Series(\n",
    "    target_perf,\n",
    "    index=[\"expected_return\", \"volatility\", \"sharpe_ratio\"],\n",
    "    name=f\"target_return_{target_return:.2%}\",\n",
    ")\n",
    "# Display weights and metrics\n",
    "target_weights_df, target_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ak6z2t0cjl7",
   "metadata": {},
   "source": [
    "## 6. Comparing unconstrained vs. constrained portfolios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa90fa8",
   "metadata": {},
   "source": [
    "### Short-Selling: Theory vs. Practice\n",
    "\n",
    "Up to now, we've been optimizing portfolios **without explicitly allowing short-selling**. PyPortfolioOpt's default behavior is `weight_bounds=(0, 1)`, which prohibits negative weights (short positions). But what if we **truly allow** unconstrained optimization?\n",
    "\n",
    "**Short-selling** means taking a **negative position** in an asset:\n",
    "\n",
    "- Borrow shares from a broker\n",
    "- Sell them immediately at current price\n",
    "- Later buy them back (hopefully at a lower price) to return to the broker\n",
    "- Profit if the price falls; lose if it rises\n",
    "\n",
    "**Why short-sell in portfolio optimization?**\n",
    "\n",
    "- **Hedge risks**: Short overvalued assets to reduce portfolio volatility\n",
    "- **Enhance returns**: Profit from expected price declines\n",
    "- **Improve efficiency**: Access to shorting expands the efficient frontier\n",
    "\n",
    "**In practice, many investors face constraints:**\n",
    "\n",
    "- **Institutional restrictions**: Pension funds, mutual funds often can't short\n",
    "- **Practical difficulties**: Requires margin accounts, involves borrowing costs\n",
    "- **Regulatory limits**: Some markets restrict short-selling\n",
    "- **Risk management**: Short positions have unlimited loss potential\n",
    "\n",
    "Let's compare **two scenarios**:\n",
    "\n",
    "1. **Unconstrained portfolios** with `weight_bounds=(-1, 1)`: Allow shorts up to -100% and longs up to +100%\n",
    "2. **Long-only portfolios** with `weight_bounds=(0, 1)`: Traditional buy-and-hold only\n",
    "\n",
    "This comparison reveals the **cost of constraints** on portfolio performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5jro76sf1k",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPARING UNCONSTRAINED VS. LONG-ONLY PORTFOLIOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# UNCONSTRAINED PORTFOLIOS (Allow short-selling)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"UNCONSTRAINED PORTFOLIOS (SHORT-SELLING ALLOWED)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Maximum Sharpe with short-selling allowed\n",
    "# weight_bounds=(-1, 1) means: -100% ≤ weight ≤ +100% for each asset\n",
    "# Negative weights = short positions, Positive weights = long positions\n",
    "ef_unconstrained_sharpe = EfficientFrontier(mu, cov_matrix, weight_bounds=(-1, 1))\n",
    "# Add L2 regularization to prevent extreme weights\n",
    "ef_unconstrained_sharpe.add_objective(objective_functions.L2_reg, gamma=0.01)\n",
    "# Optimize for maximum Sharpe ratio\n",
    "unconstrained_sharpe_weights = ef_unconstrained_sharpe.max_sharpe()\n",
    "# Clean weights (removes positions below threshold)\n",
    "cleaned_unconstrained_sharpe = ef_unconstrained_sharpe.clean_weights()\n",
    "# Calculate performance metrics\n",
    "unconstrained_sharpe_perf = ef_unconstrained_sharpe.portfolio_performance(verbose=False)\n",
    "\n",
    "print(\"\\nMaximum Sharpe Portfolio (Unconstrained):\")\n",
    "unconstrained_sharpe_df = (\n",
    "    pd.Series(cleaned_unconstrained_sharpe, name=\"weight\")\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame()\n",
    ")\n",
    "print(\"Weights:\")\n",
    "print(unconstrained_sharpe_df)\n",
    "print(f\"\\nExpected Return: {unconstrained_sharpe_perf[0]:.4f}\")\n",
    "print(f\"Volatility: {unconstrained_sharpe_perf[1]:.4f}\")\n",
    "print(f\"Sharpe Ratio: {unconstrained_sharpe_perf[2]:.4f}\")\n",
    "\n",
    "# Count short positions\n",
    "num_shorts = sum(1 for w in cleaned_unconstrained_sharpe.values() if w < 0)\n",
    "num_longs = sum(1 for w in cleaned_unconstrained_sharpe.values() if w > 0)\n",
    "print(f\"\\nShort positions: {num_shorts} assets\")\n",
    "print(f\"Long positions: {num_longs} assets\")\n",
    "\n",
    "# Minimum volatility with short-selling allowed\n",
    "ef_unconstrained_minvol = EfficientFrontier(mu, cov_matrix, weight_bounds=(-1, 1))\n",
    "# Add L2 regularization\n",
    "ef_unconstrained_minvol.add_objective(objective_functions.L2_reg, gamma=0.01)\n",
    "# Optimize for minimum volatility\n",
    "unconstrained_minvol_weights = ef_unconstrained_minvol.min_volatility()\n",
    "# Clean weights\n",
    "cleaned_unconstrained_minvol = ef_unconstrained_minvol.clean_weights()\n",
    "# Calculate performance\n",
    "unconstrained_minvol_perf = ef_unconstrained_minvol.portfolio_performance(verbose=False)\n",
    "\n",
    "print(\"\\nMinimum Volatility Portfolio (Unconstrained):\")\n",
    "unconstrained_minvol_df = (\n",
    "    pd.Series(cleaned_unconstrained_minvol, name=\"weight\")\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame()\n",
    ")\n",
    "print(\"Weights:\")\n",
    "print(unconstrained_minvol_df)\n",
    "print(f\"\\nExpected Return: {unconstrained_minvol_perf[0]:.4f}\")\n",
    "print(f\"Volatility: {unconstrained_minvol_perf[1]:.4f}\")\n",
    "print(f\"Sharpe Ratio: {unconstrained_minvol_perf[2]:.4f}\")\n",
    "\n",
    "# Count short positions\n",
    "num_shorts_mv = sum(1 for w in cleaned_unconstrained_minvol.values() if w < 0)\n",
    "num_longs_mv = sum(1 for w in cleaned_unconstrained_minvol.values() if w > 0)\n",
    "print(f\"\\nShort positions: {num_shorts_mv} assets\")\n",
    "print(f\"Long positions: {num_longs_mv} assets\")\n",
    "\n",
    "# =============================================================================\n",
    "# LONG-ONLY PORTFOLIOS (No short-selling)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LONG-ONLY PORTFOLIOS (NO SHORT-SELLING)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Maximum Sharpe with long-only constraint\n",
    "# weight_bounds=(0, 1) means: 0 ≤ weight ≤ 1 for each asset (no shorts, no leverage)\n",
    "ef_long_only = EfficientFrontier(mu, cov_matrix, weight_bounds=(0, 1))\n",
    "# Add L2 regularization\n",
    "ef_long_only.add_objective(objective_functions.L2_reg, gamma=0.01)\n",
    "# Optimize for maximum Sharpe ratio\n",
    "long_only_sharpe_weights = ef_long_only.max_sharpe()\n",
    "# Clean weights (removes positions below threshold)\n",
    "cleaned_long_only_sharpe = ef_long_only.clean_weights()\n",
    "# Calculate performance metrics\n",
    "long_only_sharpe_perf = ef_long_only.portfolio_performance(verbose=False)\n",
    "\n",
    "print(\"\\nMaximum Sharpe Portfolio (Long-only):\")\n",
    "long_only_sharpe_df = (\n",
    "    pd.Series(cleaned_long_only_sharpe, name=\"weight\")\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame()\n",
    ")\n",
    "print(\"Weights:\")\n",
    "print(long_only_sharpe_df)\n",
    "print(f\"\\nExpected Return: {long_only_sharpe_perf[0]:.4f}\")\n",
    "print(f\"Volatility: {long_only_sharpe_perf[1]:.4f}\")\n",
    "print(f\"Sharpe Ratio: {long_only_sharpe_perf[2]:.4f}\")\n",
    "\n",
    "# Minimum volatility with long-only constraint\n",
    "ef_long_only_minvol = EfficientFrontier(mu, cov_matrix, weight_bounds=(0, 1))\n",
    "# Add L2 regularization\n",
    "ef_long_only_minvol.add_objective(objective_functions.L2_reg, gamma=0.01)\n",
    "# Optimize for minimum volatility\n",
    "long_only_minvol_weights = ef_long_only_minvol.min_volatility()\n",
    "# Clean weights\n",
    "cleaned_long_only_minvol = ef_long_only_minvol.clean_weights()\n",
    "# Calculate performance\n",
    "long_only_minvol_perf = ef_long_only_minvol.portfolio_performance(verbose=False)\n",
    "\n",
    "print(\"\\nMinimum Volatility Portfolio (Long-only):\")\n",
    "long_only_minvol_df = (\n",
    "    pd.Series(cleaned_long_only_minvol, name=\"weight\")\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame()\n",
    ")\n",
    "print(\"Weights:\")\n",
    "print(long_only_minvol_df)\n",
    "print(f\"\\nExpected Return: {long_only_minvol_perf[0]:.4f}\")\n",
    "print(f\"Volatility: {long_only_minvol_perf[1]:.4f}\")\n",
    "print(f\"Sharpe Ratio: {long_only_minvol_perf[2]:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPARISON: Cost of constraints\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPACT OF SHORT-SELLING CONSTRAINT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nMaximum Sharpe Portfolio:\")\n",
    "print(\n",
    "    f\"  Unconstrained - Sharpe: {unconstrained_sharpe_perf[2]:.4f}, Vol: {unconstrained_sharpe_perf[1]:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Long-only     - Sharpe: {long_only_sharpe_perf[2]:.4f}, Vol: {long_only_sharpe_perf[1]:.4f}\"\n",
    ")\n",
    "sharpe_loss = (\n",
    "    (unconstrained_sharpe_perf[2] - long_only_sharpe_perf[2])\n",
    "    / unconstrained_sharpe_perf[2]\n",
    ") * 100\n",
    "print(f\"  → Sharpe ratio reduction: {sharpe_loss:.1f}%\")\n",
    "\n",
    "print(\"\\nMinimum Volatility Portfolio:\")\n",
    "print(\n",
    "    f\"  Unconstrained - Vol: {unconstrained_minvol_perf[1]:.4f}, Return: {unconstrained_minvol_perf[0]:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Long-only     - Vol: {long_only_minvol_perf[1]:.4f}, Return: {long_only_minvol_perf[0]:.4f}\"\n",
    ")\n",
    "vol_increase = (\n",
    "    (long_only_minvol_perf[1] - unconstrained_minvol_perf[1])\n",
    "    / unconstrained_minvol_perf[1]\n",
    ") * 100\n",
    "print(f\"  → Volatility increase: {vol_increase:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d4454",
   "metadata": {},
   "source": [
    "### Interpreting the Results: Benefits of Short-Selling\n",
    "\n",
    "**Key observations from the comparison:**\n",
    "\n",
    "**1. Negative Weights Appear in Unconstrained Portfolios**\n",
    "\n",
    "- The unconstrained portfolios now show **negative weights** (short positions)\n",
    "- These shorts are strategic: we're betting against assets expected to underperform\n",
    "- Short positions help **hedge** the portfolio and reduce overall risk\n",
    "\n",
    "**2. Performance Improvement with Short-Selling**\n",
    "\n",
    "- **Higher Sharpe Ratio**: Unconstrained portfolios achieve better risk-adjusted returns\n",
    "- **Lower Minimum Volatility**: Ability to short enables deeper risk reduction\n",
    "- **More Flexibility**: Optimizer has more tools to balance risk and return\n",
    "\n",
    "**3. Economic Interpretation of Short Positions**\n",
    "When the optimizer chooses to short an asset, it's because:\n",
    "\n",
    "- The asset has **negative alpha** (expected to underperform)\n",
    "- Shorting it provides **hedging benefits** (negative correlation with longs)\n",
    "- The position improves the **risk-return trade-off** for the overall portfolio\n",
    "\n",
    "**4. Why the Long-Only Constraint Hurts Performance**\n",
    "\n",
    "- **Reduced opportunity set**: Can only buy, not sell short\n",
    "- **Suboptimal hedging**: Can't directly bet against overvalued assets\n",
    "- **Higher risk**: Must achieve diversification only through long positions\n",
    "- **Lower returns**: Miss opportunities to profit from price declines\n",
    "\n",
    "**5. Practical Considerations**\n",
    "Despite the theoretical benefits of short-selling:\n",
    "\n",
    "- **Most retail investors** don't have access to margin accounts for shorting\n",
    "- **Institutional constraints** often prohibit shorts (e.g., mutual funds, pension funds)\n",
    "- **Costs**: Borrowing fees, margin interest, and regulatory capital requirements\n",
    "- **Risks**: Unlimited loss potential (stock price can rise indefinitely)\n",
    "\n",
    "The comparison shows that **constraints are costly**—but in practice, many investors must accept this cost due to regulatory, institutional, or risk management considerations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb11ced",
   "metadata": {},
   "source": [
    "## 7. Visualizing the efficient frontier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a247d",
   "metadata": {},
   "source": [
    "### Plotting the Efficient Frontier: Methodology\n",
    "\n",
    "To visualize the efficient frontier, we need to:\n",
    "\n",
    "1. **Generate a grid** of target returns spanning the feasible range\n",
    "2. **Solve optimization** for each target return (minimize risk subject to achieving that return)\n",
    "3. **Handle numerical issues**: Some target returns may be infeasible or cause optimization failures\n",
    "4. **Remove duplicates**: Ensure we have a clean, monotonic frontier\n",
    "\n",
    "We'll create **two frontiers**:\n",
    "\n",
    "- **Unconstrained**: Allows short-selling (weights can be negative)\n",
    "- **Long-only**: No short-selling (0 ≤ weights ≤ 1)\n",
    "\n",
    "The `compute_frontier_points()` function handles this systematically, catching optimization errors and deduplicating results.\n",
    "\n",
    "**What to expect:**\n",
    "\n",
    "- Long-only frontier lies to the **right** of the unconstrained frontier (higher risk)\n",
    "- The **tangency portfolios** differ between the two cases\n",
    "- The **gap** between frontiers shows the cost of the no-short-selling constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bb345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced efficient frontier visualization with Tidy Finance techniques\n",
    "ridge_gamma = 0.01  # Regularization parameter for all optimizations\n",
    "# Create grid of target returns to trace out the frontier\n",
    "frontier_grid = np.linspace(mu.min(), mu.max(), 50)\n",
    "\n",
    "\n",
    "def compute_frontier_points(target_returns, mu_vec, cov, gamma, weight_bounds=(-1, 1)):\n",
    "    \"\"\"\n",
    "    Sample efficient frontier points for plotting.\n",
    "\n",
    "    Args:\n",
    "        target_returns: Array of target return values to optimize for\n",
    "        mu_vec: Expected returns vector\n",
    "        cov: Covariance matrix\n",
    "        gamma: L2 regularization parameter\n",
    "        weight_bounds: Tuple of (min_weight, max_weight) for each asset\n",
    "                      (-1, 1) allows shorting; (0, 1) is long-only\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with expected_return, volatility, sharpe_ratio for each point\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for target in target_returns:\n",
    "        # Create fresh optimizer for each target\n",
    "        ef = EfficientFrontier(mu_vec, cov, weight_bounds=weight_bounds)\n",
    "        ef.add_objective(objective_functions.L2_reg, gamma=gamma)\n",
    "        try:\n",
    "            # Try to find portfolio that achieves target return with minimum risk\n",
    "            ef.efficient_return(target_return=float(target))\n",
    "            # Get performance metrics (return, volatility, Sharpe)\n",
    "            perf = ef.portfolio_performance(verbose=False)\n",
    "        except (ValueError, OverflowError):\n",
    "            # Skip this target if optimization fails (infeasible or numerical issues)\n",
    "            continue\n",
    "        rows.append(\n",
    "            {\n",
    "                \"expected_return\": perf[0],\n",
    "                \"volatility\": perf[1],\n",
    "                \"sharpe_ratio\": perf[2],\n",
    "            }\n",
    "        )\n",
    "    return (\n",
    "        pd.DataFrame(rows)\n",
    "        .drop_duplicates(subset=[\"volatility\"])  # Remove duplicate points\n",
    "        .sort_values(\"volatility\")  # Sort by increasing risk\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "# Compute frontiers with different constraints\n",
    "# Unconstrained: allows short-selling (weights between -1 and 1)\n",
    "frontier_unconstrained = compute_frontier_points(\n",
    "    frontier_grid, mu, cov_matrix, ridge_gamma, (-1, 1)\n",
    ")\n",
    "# Long-only: no short-selling (weights between 0 and 1)\n",
    "frontier_long_only = compute_frontier_points(\n",
    "    frontier_grid, mu, cov_matrix, ridge_gamma, (0, 1)\n",
    ")\n",
    "\n",
    "# Add constraint type labels for plotting\n",
    "frontier_unconstrained[\"constraint_type\"] = \"Unconstrained\"\n",
    "frontier_long_only[\"constraint_type\"] = \"Long-only\"\n",
    "\n",
    "# Combine frontiers for plotting\n",
    "all_frontiers = pd.concat(\n",
    "    [frontier_unconstrained, frontier_long_only], ignore_index=True\n",
    ")\n",
    "\n",
    "# Individual asset positions (for reference on plot)\n",
    "asset_positions = pd.DataFrame(\n",
    "    {\n",
    "        \"symbol\": mu.index,\n",
    "        \"expected_return\": mu,\n",
    "        \"volatility\": np.sqrt(np.diag(cov_matrix)),  # Square root of variance\n",
    "    }\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Key portfolios with different constraints (for annotation on plot)\n",
    "key_portfolios = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"portfolio\": \"Min Vol (Unconstrained)\",\n",
    "            \"expected_return\": unconstrained_minvol_perf[0],\n",
    "            \"volatility\": unconstrained_minvol_perf[1],\n",
    "            \"constraint_type\": \"Unconstrained\",\n",
    "        },\n",
    "        {\n",
    "            \"portfolio\": \"Max Sharpe (Unconstrained)\",\n",
    "            \"expected_return\": unconstrained_sharpe_perf[0],\n",
    "            \"volatility\": unconstrained_sharpe_perf[1],\n",
    "            \"constraint_type\": \"Unconstrained\",\n",
    "        },\n",
    "        {\n",
    "            \"portfolio\": \"Target (Unconstrained)\",\n",
    "            \"expected_return\": target_perf[0],\n",
    "            \"volatility\": target_perf[1],\n",
    "            \"constraint_type\": \"Unconstrained\",\n",
    "        },\n",
    "        {\n",
    "            \"portfolio\": \"Min Vol (Long-only)\",\n",
    "            \"expected_return\": long_only_minvol_perf[0],\n",
    "            \"volatility\": long_only_minvol_perf[1],\n",
    "            \"constraint_type\": \"Long-only\",\n",
    "        },\n",
    "        {\n",
    "            \"portfolio\": \"Max Sharpe (Long-only)\",\n",
    "            \"expected_return\": long_only_sharpe_perf[0],\n",
    "            \"volatility\": long_only_sharpe_perf[1],\n",
    "            \"constraint_type\": \"Long-only\",\n",
    "        },\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32746eb8",
   "metadata": {},
   "source": [
    "### Interpreting the Efficient Frontier Plot\n",
    "\n",
    "This comprehensive visualization shows:\n",
    "\n",
    "**1. The Efficient Frontiers (curved lines):**\n",
    "\n",
    "- **Blue line** (Unconstrained): Efficient frontier allowing short positions\n",
    "- **Orange line** (Long-only): Efficient frontier with no-short-selling constraint\n",
    "- Notice how the long-only frontier lies to the **right** → constraints increase risk\n",
    "\n",
    "**2. Individual Assets (gray points):**\n",
    "\n",
    "- Any portfolio on the efficient frontier **dominates** individual assets\n",
    "- Diversification creates portfolios superior to holding single stocks\n",
    "\n",
    "**3. Key Portfolios (colored markers):**\n",
    "\n",
    "- **Circles**: Unconstrained portfolios\n",
    "- **Triangles**: Long-only portfolios\n",
    "- Compare positions to see impact of constraints\n",
    "\n",
    "**Key insights:**\n",
    "\n",
    "- **Diversification benefits**: Efficient portfolios achieve lower risk than any individual asset\n",
    "- **Cost of constraints**: Long-only constraint reduces Sharpe ratio and increases minimum achievable risk\n",
    "- **Tangency portfolio**: The highest Sharpe ratio point on each frontier\n",
    "- **Practical implications**: If you can't short-sell, you must accept either lower returns or higher risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7644ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced plot with Tidy Finance styling\n",
    "enhanced_plot = (\n",
    "    # Initialize empty plot (we'll add multiple layers)\n",
    "    ggplot()\n",
    "    # Add efficient frontier lines (one for each constraint type)\n",
    "    + geom_line(\n",
    "        all_frontiers,\n",
    "        aes(x=\"volatility\", y=\"expected_return\", color=\"constraint_type\"),\n",
    "        size=1.2,\n",
    "    )\n",
    "    # Add individual asset positions as reference points\n",
    "    + geom_point(\n",
    "        asset_positions,\n",
    "        aes(x=\"volatility\", y=\"expected_return\"),\n",
    "        color=\"#6c757d\",  # Neutral gray color\n",
    "        size=3,\n",
    "        alpha=0.7,  # Semi-transparent\n",
    "    )\n",
    "    # Add labels for individual assets (with automatic positioning to avoid overlap)\n",
    "    + geom_text(\n",
    "        asset_positions,\n",
    "        aes(x=\"volatility\", y=\"expected_return\", label=\"symbol\"),\n",
    "        adjust_text={\"arrowprops\": {\"arrowstyle\": \"-\"}},\n",
    "        size=9,\n",
    "        color=\"#495057\",\n",
    "    )\n",
    "    # Add key portfolio positions (MVP, Max Sharpe, etc.)\n",
    "    + geom_point(\n",
    "        key_portfolios,\n",
    "        aes(\n",
    "            x=\"volatility\",\n",
    "            y=\"expected_return\",\n",
    "            color=\"constraint_type\",\n",
    "            shape=\"constraint_type\",  # Different shapes for different constraints\n",
    "        ),\n",
    "        size=4,\n",
    "    )\n",
    "    # Add labels for key portfolios\n",
    "    + geom_text(\n",
    "        key_portfolios,\n",
    "        aes(x=\"volatility\", y=\"expected_return\", label=\"portfolio\"),\n",
    "        adjust_text={\"arrowprops\": {\"arrowstyle\": \"-\"}},\n",
    "        size=8,\n",
    "        color=\"#1b263b\",\n",
    "    )\n",
    "    # Format x-axis as percentages\n",
    "    + scale_x_continuous(labels=percent_format())\n",
    "    # Format y-axis as percentages\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    # Manual color scale (professional color scheme)\n",
    "    + scale_color_manual(values={\"Unconstrained\": \"#0d3b66\", \"Long-only\": \"#fb8500\"})\n",
    "    # Manual shape scale (circles for unconstrained, triangles for long-only)\n",
    "    + scale_shape_manual(values={\"Unconstrained\": \"o\", \"Long-only\": \"^\"})\n",
    "    # Add comprehensive labels\n",
    "    + labs(\n",
    "        title=\"Efficient Frontier: Impact of Short-Selling Constraints\",\n",
    "        subtitle=\"Comparing unconstrained vs. long-only portfolios\",\n",
    "        x=\"Volatility (annualised)\",\n",
    "        y=\"Expected Return (annualised)\",\n",
    "        color=\"Constraint\",\n",
    "        shape=\"Constraint\",\n",
    "        caption=\"Data: Historical returns with L2 regularisation (γ=0.01)\",\n",
    "    )\n",
    "    # Use minimal theme for clean look\n",
    "    + theme_minimal()\n",
    "    # Set custom figure size\n",
    "    + theme(figure_size=(12, 8))\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "enhanced_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d309b6",
   "metadata": {},
   "source": [
    "### Comparing Portfolio Weights Across Strategies\n",
    "\n",
    "Understanding **how** different strategies allocate capital across assets is crucial for:\n",
    "\n",
    "1. **Implementation**: Do we need short-selling capability?\n",
    "2. **Risk management**: Are we overly concentrated in few assets?\n",
    "3. **Transaction costs**: Extreme weights may be costly to establish\n",
    "4. **Interpretation**: Why does this portfolio work?\n",
    "\n",
    "The weight comparison table shows:\n",
    "\n",
    "- **Positive weights**: Long positions (buy and hold)\n",
    "- **Negative weights**: Short positions (borrow and sell)\n",
    "- **Zero weights**: Assets excluded from the portfolio\n",
    "\n",
    "**What to look for:**\n",
    "\n",
    "- **Concentration**: Are weights spread across many assets or focused on a few?\n",
    "- **Short positions**: How important is short-selling to achieving optimal results?\n",
    "- **Stability**: Do small changes in optimization parameters lead to dramatic weight changes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g5pwq7x6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio weights comparison visualization\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PORTFOLIO WEIGHTS COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compile all portfolio weights (excluding custom constraints for now)\n",
    "# Each column represents one portfolio strategy\n",
    "weights_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Max Sharpe (Uncon.)\": pd.Series(\n",
    "            cleaned_unconstrained_sharpe\n",
    "        ),  # Maximum Sharpe, unconstrained\n",
    "        \"Min Vol (Uncon.)\": pd.Series(\n",
    "            cleaned_unconstrained_minvol\n",
    "        ),  # Minimum volatility, unconstrained\n",
    "        \"Max Sharpe (Long)\": pd.Series(\n",
    "            cleaned_long_only_sharpe\n",
    "        ),  # Maximum Sharpe, long-only\n",
    "        \"Min Vol (Long)\": pd.Series(\n",
    "            cleaned_long_only_minvol\n",
    "        ),  # Minimum volatility, long-only\n",
    "    }\n",
    ").fillna(\n",
    "    0\n",
    ")  # Replace NaN with 0 (assets not included in portfolio)\n",
    "\n",
    "print(\"Portfolio weights summary:\")\n",
    "print(weights_comparison)\n",
    "\n",
    "# Create stacked bar chart with better styling\n",
    "# Reshape data from wide to long format for ggplot\n",
    "weights_long = (\n",
    "    weights_comparison.reset_index()\n",
    "    .melt(id_vars=\"index\", var_name=\"Portfolio\", value_name=\"Weight\")\n",
    "    .rename(columns={\"index\": \"Asset\"})\n",
    ")\n",
    "\n",
    "# Add constraint type for coloring\n",
    "weights_long[\"Constraint_Type\"] = weights_long[\"Portfolio\"].apply(\n",
    "    lambda x: \"Long-only\" if \"Long\" in x else \"Unconstrained\"\n",
    ")\n",
    "\n",
    "# Sort portfolios for better display (explicit ordering)\n",
    "weights_long[\"Portfolio\"] = pd.Categorical(\n",
    "    weights_long[\"Portfolio\"],\n",
    "    categories=[\n",
    "        \"Max Sharpe (Uncon.)\",\n",
    "        \"Min Vol (Uncon.)\",\n",
    "        \"Max Sharpe (Long)\",\n",
    "        \"Min Vol (Long)\",\n",
    "    ],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "# Create stacked bar chart\n",
    "weights_plot = (\n",
    "    ggplot(weights_long, aes(x=\"Portfolio\", y=\"Weight\", fill=\"Asset\"))\n",
    "    # Stacked bars showing composition of each portfolio\n",
    "    + geom_col(position=\"stack\", width=0.7)\n",
    "    # Add horizontal line at zero to clearly show short positions\n",
    "    + geom_hline(yintercept=0, linetype=\"dashed\", color=\"black\", alpha=0.5)\n",
    "    # Format y-axis as percentages\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    # Add comprehensive labels\n",
    "    + labs(\n",
    "        title=\"Portfolio Weights Across Different Optimization Strategies\",\n",
    "        subtitle=\"Comparing unconstrained vs. constrained portfolios\",\n",
    "        x=\"Portfolio Strategy\",\n",
    "        y=\"Portfolio Weight\",\n",
    "        caption=\"Negative weights indicate short positions\",\n",
    "    )\n",
    "    # Use minimal theme\n",
    "    + theme_minimal()\n",
    "    # Rotate x-axis labels for readability\n",
    "    + theme(\n",
    "        axis_text_x=element_text(angle=45, hjust=1),\n",
    "        figure_size=(12, 7),\n",
    "        legend_position=\"right\",\n",
    "    )\n",
    "    # Customize legend\n",
    "    + guides(fill=guide_legend(title=\"Asset\"))\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "weights_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a31826",
   "metadata": {},
   "source": [
    "## 8. From weights to a trade list\n",
    "\n",
    "Optimized weights rarely translate directly into actual trades. PyPortfolioOpt includes a discrete allocator that converts optimal weights into real share counts given your budget.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87387dc",
   "metadata": {},
   "source": [
    "### Understanding Discrete Allocation\n",
    "\n",
    "Portfolio optimization produces **continuous weights** (e.g., 15.34% in Apple, 8.72% in Microsoft). However, in practice:\n",
    "\n",
    "- **Stocks trade in whole shares**: You can't buy 0.34 shares of Apple\n",
    "- **Budget constraints**: You have a fixed amount to invest\n",
    "- **Transaction costs**: Fractional positions may be expensive or impossible\n",
    "\n",
    "**Discrete allocation** solves this problem by converting optimal weights into **integer share counts** that:\n",
    "\n",
    "1. Respect your budget constraint\n",
    "2. Approximate the optimal weights as closely as possible\n",
    "3. Are practically implementable\n",
    "\n",
    "The `DiscreteAllocation` class uses a **greedy algorithm**:\n",
    "\n",
    "- Start with the most important positions\n",
    "- Allocate whole shares until budget is exhausted\n",
    "- Minimize tracking error vs. the target weights\n",
    "\n",
    "**What you get:**\n",
    "\n",
    "- **Allocation dictionary**: How many shares of each stock to buy\n",
    "- **Leftover cash**: Uninvested capital (due to discrete constraint and rounding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most recent price for each asset (needed for share count calculation)\n",
    "latest_prices = get_latest_prices(prices_wide)\n",
    "# Set portfolio budget (how much capital we have to invest)\n",
    "portfolio_value = 10_000\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DISCRETE ALLOCATION FOR LONG-ONLY MAX SHARPE PORTFOLIO\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: Discrete allocation works only for long-only portfolios.\")\n",
    "print(\"Short positions cannot be represented as negative share counts.\\n\")\n",
    "\n",
    "# Create discrete allocation object with:\n",
    "# - Target weights (from long-only maximum Sharpe portfolio)\n",
    "# - Latest prices (to convert $ amounts to share counts)\n",
    "# - Total budget (portfolio value)\n",
    "da = DiscreteAllocation(\n",
    "    cleaned_long_only_sharpe, latest_prices, total_portfolio_value=portfolio_value\n",
    ")\n",
    "# Run greedy allocation algorithm to determine share counts\n",
    "# Returns: (1) dictionary of {symbol: shares}, (2) leftover cash\n",
    "allocation, leftover_cash = da.greedy_portfolio()\n",
    "\n",
    "# Display results\n",
    "print(\"Share allocation:\")\n",
    "allocation_df = pd.Series(allocation, name=\"shares\").sort_index()\n",
    "print(allocation_df)\n",
    "print(f\"\\nLeftover cash: ${leftover_cash:.2f}\")\n",
    "\n",
    "# Calculate total invested\n",
    "total_invested = sum(\n",
    "    allocation[symbol] * latest_prices[symbol] for symbol in allocation\n",
    ")\n",
    "print(f\"Total invested: ${total_invested:.2f}\")\n",
    "print(f\"Portfolio utilization: {(total_invested/portfolio_value)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c5b0f",
   "metadata": {},
   "source": [
    "### Why We Use Long-Only for Discrete Allocation\n",
    "\n",
    "The discrete allocation algorithm **cannot handle short positions** because:\n",
    "\n",
    "1. **Shares must be non-negative integers**: You can't buy -5 shares\n",
    "2. **Short-selling mechanics differ**: Shorting requires borrowing shares, not just negative quantities\n",
    "3. **Practical implementation**: Most brokers handle shorts separately from longs\n",
    "\n",
    "For the **unconstrained portfolio with shorts**, implementation would require:\n",
    "\n",
    "- Separate orders for long positions (buy) and short positions (borrow and sell)\n",
    "- Margin account with sufficient collateral\n",
    "- Tracking of borrowing costs and margin requirements\n",
    "- More complex position management\n",
    "\n",
    "Therefore, we demonstrate discrete allocation using the **long-only Max Sharpe portfolio**, which can be directly implemented through standard buy orders.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cflabs (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
